{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIsEHpNoycm3qy4x2kMMoD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/move37-labs/nucleobench/blob/documentation/nucleobench/colab/custom_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJj-RIWapMZc"
      },
      "outputs": [],
      "source": [
        "# `nucleopt` is a minimal package that has nucleobench optimizers.\n",
        "# For the full library, including tasks, install `nucleobench`.\n",
        "!pip install nucleobench"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Non-gradient designers, like AdaBeam, can use tasks described simply as a function (also [AdaLead](https://arxiv.org/abs/2010.02141), Directed Evolution, Ordered Beam, Unordered Beam)\n",
        "\n",
        "1. Torch designers, like [Ledidi](https://www.biorxiv.org/content/10.1101/2020.05.21.109686v1), require a task class with gradients defined (also [FastSeqProp](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-021-04437-5))\n",
        "\n",
        "1. TISM designers, like Gradient Evo, require a task class with [Taylor In-Silico Mutagenesis](https://www.sciencedirect.com/science/article/pii/S2589004224020327) defined."
      ],
      "metadata": {
        "id": "FFcL3E0Ssva3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Style 1: Task as a simple function."
      ],
      "metadata": {
        "id": "9HRqoH3zw-ww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Define the task.\n",
        "import re\n",
        "def count_regular_expression(seqs: list[str]) -> float:\n",
        "  \"\"\"Counts the number of occurances of 'ACT'\"\"\"\n",
        "  # Use lookaheads so we allow overlapping regions.\n",
        "  # Designers minimize function.\n",
        "  return [-1 * float(len(re.findall('(?=(ACT))', s))) for s in seqs]\n",
        "\n",
        "# Step 2: Define the designer.\n",
        "from nucleobench import optimizations\n",
        "opt_obj = optimizations.get_optimization('adabeam')\n",
        "# Every task has some baseline, default arguments to initialize.\n",
        "opt_init_args = opt_obj.debug_init_args()\n",
        "opt_init_args['model_fn'] = count_regular_expression\n",
        "opt_init_args['start_sequence'] = 'C' * 10\n",
        "designer = opt_obj(**opt_init_args)\n",
        "\n",
        "# Step 3: Run the designer and show the results.\n",
        "designer.run(n_steps=100)\n",
        "ret = designer.get_samples(1)\n",
        "ret_score = count_regular_expression(ret)\n",
        "print(f'Final score: {ret_score[0]}')\n",
        "print(f'Final sequence: {ret[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sqmtWWGpmgC",
        "outputId": "9b2200fe-c26d-44a0-9398-f1551ce0c536"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 99 current scores: [np.float64(3.0), np.float64(3.0), np.float64(3.0), np.float64(3.0), np.float64(3.0), np.float64(2.0), np.float64(2.0), np.float64(2.0), np.float64(2.0), np.float64(2.0)]\n",
            "Final score: -3.0\n",
            "Final sequence: ACTTACTACT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple functions on gradient designers will fail."
      ],
      "metadata": {
        "id": "PWEz1q4rxFtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt_obj = optimizations.get_optimization('ledidi')\n",
        "opt_init_args = opt_obj.debug_init_args()\n",
        "opt_init_args['model_fn'] = count_regular_expression\n",
        "opt_init_args['start_sequence'] = 'C' * 100\n",
        "designer = opt_obj(**opt_init_args)  # Will fail."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "SGTGKuiYxIY0",
        "outputId": "f2e54d81-6e37-46e7-aad2-1d6e00d7d728"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'function' object has no attribute 'model'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-391848041.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mopt_init_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_fn'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_regular_expression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mopt_init_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start_sequence'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'C'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdesigner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mopt_init_args\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Will fail.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nucleobench/optimizations/ledidi/ledidi.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_fn, start_sequence, positions_to_mutate, vocab, train_batch_size, lr, use_input_loss, rng_seed, debug)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'model'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Style 2: Task as a PyTorch differentiable object."
      ],
      "metadata": {
        "id": "qftui9ZQxUCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a differentiable PyTorch model that counts substrings."
      ],
      "metadata": {
        "id": "ll4mJvziyo1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from nucleobench.common import constants\n",
        "from nucleobench.common import string_utils\n",
        "from nucleobench.optimizations import model_class as mc\n",
        "\n",
        "# Step 1: Define the task class.\n",
        "\n",
        "class CountSubstringModel(torch.nn.Module, mc.PyTorchDifferentiableModel):\n",
        "    \"\"\"Count number of substrings, using convs.\"\"\"\n",
        "    def __init__(self, substring: str, vocab: list[str] = constants.VOCAB):\n",
        "        super().__init__()\n",
        "        self.substring = substring\n",
        "        self.vocab = vocab\n",
        "\n",
        "        self.substr_tensor = string_utils.dna2tensor(\n",
        "            substring, vocab_list=self.vocab)\n",
        "        self.substr_tensor = torch.unsqueeze(self.substr_tensor, dim=0)\n",
        "        self.substr_tensor.requires_grad = False\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        assert x.ndim == 3\n",
        "        assert x.shape[1] == 4, x.shape\n",
        "        out_tensor = F.conv1d(x, self.substr_tensor)\n",
        "        out_tensor = torch.squeeze(out_tensor, 1)\n",
        "        out_tensor = torch.square(out_tensor)  # Square to incentivize exact matches.\n",
        "        out_tensor = torch.sum(out_tensor, dim=1)\n",
        "        return -1 * out_tensor  # Flip sign so we minimize.\n",
        "\n",
        "    def inference_on_tensor(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.forward(x)\n",
        "\n",
        "    def __call__(self, seqs: list[str]):\n",
        "        torch_seq = string_utils.dna2tensor_batch(seqs)\n",
        "        result = self.forward(torch_seq)\n",
        "        assert result.ndim == 1, result.shape\n",
        "        return [float(x) for x in result]\n",
        "\n",
        "\n",
        "# Step 2: Instantiate the class (and sanity test it).\n",
        "count_substring_model = CountSubstringModel('ACT')\n",
        "assert count_substring_model(['ACT'])[0] == -(3**2)\n",
        "assert count_substring_model(['ACTACT'])[0] == -(3**2 + 3**2)\n",
        "assert count_substring_model(['ACTCT'])[0] == -(3**2 + 2**2)\n",
        "\n",
        "# Step 3: Define the designer.\n",
        "from nucleobench import optimizations\n",
        "opt_obj = optimizations.get_optimization('ledidi')\n",
        "designer = opt_obj(\n",
        "    model_fn = count_substring_model,\n",
        "    start_sequence = 'C' * 10,\n",
        "    rng_seed=0)\n",
        "\n",
        "# Step 3: Run the designer and show the results.\n",
        "_ = designer.run(n_steps=1000)\n",
        "ret = designer.get_samples(1)\n",
        "ret_score = count_substring_model(ret)\n",
        "print(f'Final score: {ret_score[0]}')\n",
        "print(f'Final sequence: {ret[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ybztB7L66JL",
        "outputId": "27ccb2e1-eec8-4bec-e0b6-5583bc886f5a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final score: -28.0\n",
            "Final sequence: ACTACTCACT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Style 3: Task as a TISM-aware object."
      ],
      "metadata": {
        "id": "3cS63SoBBnDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from nucleobench.common import constants\n",
        "from nucleobench.common import attribution_lib_torch as att_lib\n",
        "from nucleobench.common import string_utils\n",
        "\n",
        "from nucleobench.optimizations import model_class as mc\n",
        "\n",
        "class CountSubstringModel(torch.nn.Module, mc.TISMModelClass):\n",
        "    \"\"\"Count number of substrings, using convs.\"\"\"\n",
        "    def __init__(self, substring: str, vocab: list[str] = constants.VOCAB):\n",
        "        super().__init__()\n",
        "        self.substring = substring\n",
        "        self.vocab = vocab\n",
        "\n",
        "        self.substr_tensor = string_utils.dna2tensor(\n",
        "            substring, vocab_list=self.vocab)\n",
        "        self.substr_tensor = torch.unsqueeze(self.substr_tensor, dim=0)\n",
        "        self.substr_tensor.requires_grad = False\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        assert x.ndim == 3\n",
        "        assert x.shape[1] == 4, x.shape\n",
        "        out_tensor = F.conv1d(x, self.substr_tensor)\n",
        "        out_tensor = torch.squeeze(out_tensor, 1)\n",
        "        out_tensor = torch.square(out_tensor)  # Square to incentivize exact matches.\n",
        "        out_tensor = torch.sum(out_tensor, dim=1)\n",
        "        return -1 * out_tensor  # Flip sign so we minimize.\n",
        "\n",
        "    def inference_on_tensor(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.forward(x)\n",
        "\n",
        "    def tism(self, x: str, idxs: Optional[list[int]] = None) -> tuple[torch.Tensor, list[dict[str, torch.Tensor]]]:\n",
        "        input_tensor = string_utils.dna2tensor(x, vocab_list=self.vocab)\n",
        "        sg_tensor = att_lib.smoothgrad_torch(\n",
        "            input_tensor=input_tensor,\n",
        "            model=self.inference_on_tensor,\n",
        "            noise_stdev=0.0,\n",
        "            times=1,\n",
        "            idxs=idxs,\n",
        "        )\n",
        "        sg = att_lib.smoothgrad_tensor_to_dict(sg_tensor, vocab=self.vocab)\n",
        "        x_effective = x if idxs is None else [x[idx] for idx in idxs]\n",
        "        sg = att_lib.smoothgrad_to_tism(sg, x_effective)\n",
        "        y = self.inference_on_tensor(torch.unsqueeze(input_tensor, dim=0))\n",
        "        return y, sg\n",
        "\n",
        "    def __call__(self, seqs: list[str]):\n",
        "        torch_seq = string_utils.dna2tensor_batch(seqs)\n",
        "        result = self.inference_on_tensor(torch_seq)\n",
        "        assert result.ndim == 1, result.shape\n",
        "        return [float(x) for x in result]\n",
        "\n",
        "# Step 2: Instantiate the class (and sanity test it).\n",
        "count_substring_model = CountSubstringModel('ACT')\n",
        "assert count_substring_model(['ACT'])[0] == -(3**2)\n",
        "assert count_substring_model(['ACTACT'])[0] == -(3**2 + 3**2)\n",
        "assert count_substring_model(['ACTCT'])[0] == -(3**2 + 2**2)\n",
        "\n",
        "# Step 3: Define the designer.\n",
        "from nucleobench import optimizations\n",
        "opt_obj = optimizations.get_optimization('directed_evolution')\n",
        "designer = opt_obj(\n",
        "    model_fn = count_substring_model,\n",
        "    start_sequence = 'C' * 10,\n",
        "    use_tism=True,\n",
        "    location_only=False,\n",
        "    budget=10,\n",
        "    fraction_tism=1.0,\n",
        "    rnd_seed=0)\n",
        "\n",
        "# Step 3: Run the designer and show the results.\n",
        "_ = designer.run(n_steps=7)\n",
        "ret = designer.get_samples(2)\n",
        "ret_score = count_substring_model(ret)\n",
        "print(f'Final score: {ret_score}')\n",
        "print(f'Final sequence: {ret}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDbNLdT6BqG1",
        "outputId": "fef0e366-ff9b-489e-8ded-0053e47cb5a4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsed TISM args: TISMArgs(location_only=False, budget=10, fraction_tism=1.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:01<00:00,  4.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best score: -28.0\n",
            "Final score: [-28.0]\n",
            "Final sequence: ['ACTACTCACT']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}